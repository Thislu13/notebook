# 过拟合与欠拟

# 过拟合 Overfitting

> 模型仅简单记住了训练数据与结果之间的关系  
>
> 表现为 训练误差 明显低于 验证误差

* 训练误差 与 泛化误差  前者指在训练集上的误差，后者指 模型应用在同样从原始样本的分布中抽取的无限多数据样本时，模型误差的期望。

  > 我们希望训练集与测试集从相同特征中独立同分布提取

* 导致过拟合的常见原因

  * 可调节参数的数量过多
  * 参数采用值的数据范围过大
  * 训练样本的数量过少

* 解决方法

  * 正则化

## 欠拟合 Underfitting

> 表现为 训练集和验证集表现都比较差，但是他们的差距并不大

此时我们有理由认为是模型学习能力差，通过提升模型复杂度能得到更好的结果

# 数据集划分

## 测试数据集

确定所有超参前尽量不使用训练集，原则上测试集只使用一次，避免对测试集的过拟合

* K则交叉验证 

  将数据集划分为K个不重合的子集，每次选其中 K-1 作为训练集，其中一份作为验证集



# 权重衰退(正则化)

>  使用限制参数值的选择范围来控制模型容量

$$
||x||^2 \leq \theta
$$

实际中常常在损失函数中加入一个  **罚**（拉格朗日得到）
$$
+\frac{\lambda}{2}||W||^2
$$
计算梯度
$$
\frac{\partial (L(W,b)+\frac{\lambda}{2}||W||^2)}{\partial W} = \frac{\partial L(W,b)}{\partial W} + \lambda W
$$
考虑到参数随时间更新 $$W_{t+1}$$ 的值
$$
W_{t+1} = W_{t} - \eta(\frac{\partial L(W_{t},b)}{\partial W_{t}}+ \lambda W_{t})\\=(1-\eta\lambda)W_{t} - \eta\frac{\partial L(W_{t},b)}{\partial W_{t}}
$$
通常 $$\eta\lambda<1$$  因此又称权重衰退

# Drop out

> 常用于全连接层

 随机的舍弃掉上一层的一些输出，让本层的权重无法发挥作用
$$
x^{'}_{i}\left\{
\begin{aligned}
x & = & 0 &&with&&probablity&&p\\
y & = & \frac{x_{i}}{1-p}&&otherrise\\
\end{aligned}
\right.
$$
抛弃一些，将剩余的放大

![image-20240811162219238](https://raw.githubusercontent.com/Thislu13/image_save/main/notebook/202408111622227.png)
