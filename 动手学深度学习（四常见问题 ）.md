# 过拟合与欠拟

# 过拟合 Overfitting

> 模型仅简单记住了训练数据与结果之间的关系  
>
> 表现为 训练误差 明显低于 验证误差

* 训练误差 与 泛化误差  前者指在训练集上的误差，后者指 模型应用在同样从原始样本的分布中抽取的无限多数据样本时，模型误差的期望。

  > 我们希望训练集与测试集从相同特征中独立同分布提取

* 导致过拟合的常见原因

  * 可调节参数的数量过多
  * 参数采用值的数据范围过大
  * 训练样本的数量过少

* 解决方法

  * 正则化

## 欠拟合 Underfitting

> 表现为 训练集和验证集表现都比较差，但是他们的差距并不大

此时我们有理由认为是模型学习能力差，通过提升模型复杂度能得到更好的结果

# 数据集划分

## 测试数据集

确定所有超参前尽量不使用训练集，原则上测试集只使用一次，避免对测试集的过拟合

* K则交叉验证 

  将数据集划分为K个不重合的子集，每次选其中 K-1 作为训练集，其中一份作为验证集

# 为什么要随机初始化参数

* 如果模型第一层权重相同，在反向传播的过程中就会学到相同的内容，多个权重失去意义

初始化方法

* MXNet默认

  每个元素设置为 -0.07 - 0.07之间的均匀分布，偏置清零

* Xavier
  $$
  U\Big( -\sqrt{\frac{6}{a+b}}, \sqrt{\frac{6}{a+b}}\Big)
  $$

# 环境和分布偏移

## 协变量偏移

>  条件映射没有改变 $$P(y|X)$$
>
> 但是$$X$$自身的分布发生偏移  特征分布变化

## 标签偏移



