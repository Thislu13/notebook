# 过拟合与欠拟

# 过拟合 Overfitting

> 模型仅简单记住了训练数据与结果之间的关系  
>
> 表现为 训练误差 明显低于 验证误差

* 训练误差 与 泛化误差  前者指在训练集上的误差，后者指 模型应用在同样从原始样本的分布中抽取的无限多数据样本时，模型误差的期望。

  > 我们希望训练集与测试集从相同特征中独立同分布提取

* 导致过拟合的常见原因

  * 可调节参数的数量过多
  * 参数采用值的数据范围过大
  * 训练样本的数量过少

* 解决方法

  * 正则化

## 欠拟合 Underfitting

> 表现为 训练集和验证集表现都比较差，但是他们的差距并不大

此时我们有理由认为是模型学习能力差，通过提升模型复杂度能得到更好的结果

# 数据集划分

## 测试数据集

确定所有超参前尽量不使用训练集，原则上测试集只使用一次，避免对测试集的过拟合

* K则交叉验证 

  将数据集划分为K个不重合的子集，每次选其中 K-1 作为训练集，其中一份作为验证集