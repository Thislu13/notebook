# 算法基础

## 基于锚框

### 锚框方法

> 算法对边框的猜测，往往是先生成多个框，预测锚框内是否有关注的物体，最后预测锚框到真实边缘的偏移

![image-20241110165955966](https://raw.githubusercontent.com/Thislu13/image_save/main/notebook/202411101700058.png)

对于每一个边缘框都找到一个IOU最大的锚框，剩余锚框的处理可以全部设置为负样本也可以设置为IOU最大的边缘框类别。

每张图片读进之后，推理锚框，生成多组训练数据

![image-20241114171023934](https://raw.githubusercontent.com/Thislu13/image_save/main/notebook/202411141710987.png)

如果一个锚框没有被分配真实边界框，我们只需将锚框的类别标记为**背景**

### 锚框的具体实现

对于每一个像素点找该点开始的锚框

锚框的高宽分别是 $ws\sqrt{r}$、$\frac{hs}{\sqrt{r}}$

> wh是原图像的尺寸， s是目标框占原图像百分比，r是高宽之比（这里的宽高之比对应的是1:1条件下的比例,因此实际计算时由映射操作）

给出一组$(s_{1}, r_{1})\cdots$ 进行锚框

![image-20241114163612223](https://raw.githubusercontent.com/Thislu13/image_save/main/notebook/202411141636323.png)

```python
def multibox_prior(data, sizes, ratios):
    """生成以每个像素为中心具有不同形状的锚框"""
    in_height, in_width = data.shape[-2:]
    device, num_sizes, num_ratios = data.device, len(sizes), len(ratios)
    boxes_per_pixel = (num_sizes + num_ratios - 1)
    size_tensor = torch.tensor(sizes, device=device)
    ratio_tensor = torch.tensor(ratios, device=device)

    # 为了将锚点移动到像素的中心，需要设置偏移量。
    # 因为一个像素的高为1且宽为1，我们选择偏移我们的中心0.5
    offset_h, offset_w = 0.5, 0.5
    steps_h = 1.0 / in_height  # 在y轴上缩放步长
    steps_w = 1.0 / in_width  # 在x轴上缩放步长

    # 生成锚框的所有中心点
    center_h = (torch.arange(in_height, device=device) + offset_h) * steps_h
    center_w = (torch.arange(in_width, device=device) + offset_w) * steps_w
    shift_y, shift_x = torch.meshgrid(center_h, center_w, indexing='ij')
    shift_y, shift_x = shift_y.reshape(-1), shift_x.reshape(-1)

    # 生成“boxes_per_pixel”个高和宽，
    # 之后用于创建锚框的四角坐标(xmin,xmax,ymin,ymax), 输入的图片可能不符合1：1的长宽比，需要做变形处理
    w = torch.cat((size_tensor * torch.sqrt(ratio_tensor[0]),
                   sizes[0] * torch.sqrt(ratio_tensor[1:])))\
                   * in_height / in_width  # 处理矩形输入
    h = torch.cat((size_tensor / torch.sqrt(ratio_tensor[0]),
                   sizes[0] / torch.sqrt(ratio_tensor[1:])))
    # 除以2来获得半高和半宽
    anchor_manipulations = torch.stack((-w, -h, w, h)).T.repeat(
                                        in_height * in_width, 1) / 2

    # 每个中心点都将有“boxes_per_pixel”个锚框，
    # 所以生成含所有锚框中心的网格，重复了“boxes_per_pixel”次
    out_grid = torch.stack([shift_x, shift_y, shift_x, shift_y],
                dim=1).repeat_interleave(boxes_per_pixel, dim=0)
    output = out_grid + anchor_manipulations
    return output.unsqueeze(0)
```

### 偏移的计算方法（锚框与边缘框之间的偏移 ）

其中方法之一

![image-20241114171645469](https://raw.githubusercontent.com/Thislu13/image_save/main/notebook/202411141716497.png)

### 非极大值抑制NMS 

选中非背景类的最大预测值，去掉所有其他和它IOU大于$\theta$的预测，循环执行

![image-20241114172715278](https://raw.githubusercontent.com/Thislu13/image_save/main/notebook/202411141727319.png)

### 多尺度锚框

我们通过对不同层的 特征图 进行锚框，从而实现多尺度锚框，这样做的好处有：

* **适应目标的多样性**， 在不同层的特征图中，每一个锚框中心点所代表的对应原始图片面积均不相同，从而对不同尺度的目标进行检测
  * **浅层特征图**分辨率高，适合小目标
  * **深层特征图**分辨率低，适合大目标
* **提高计算效率**，在特征图上生成锚框的计算成本较低（相较于原始尺寸，生成更少的目标框）

## 非锚框



# 常见算法

## R-CNN系列

### R-CNN

### Fast R-CNN

### Faster R-CNN

### Mask R-CNN

## SSD系列

[[ssd原理及实现]]

## YOLO系列

## center_net





# 评价指标

## IoU

> IoU(Intersection Over Union) 交并占比 ，表示预测框和真实框的相近程度。

$$
IoU =  \frac{A\bigcap B}{A\bigcup B}
$$

A、B分别表示预测框与真实框

![image-20240805172732713](https://raw.githubusercontent.com/Thislu13/image_save/main/notebook/202408051727491.png)

> 有其他变种 CIoU、DIoU、GIoU

## TP、FP、TN、FN

![image-20240805172917617](https://raw.githubusercontent.com/Thislu13/image_save/main/notebook/202408051729237.png)

>  TP、FP 通过 IoU 阈值来判断预测结果
>
> **TP** 预测值大于阈值、IoU大于I阈值 （对于单个目标TP只有一个，在大于IoU的框里，选择IoU值最大的一个预测框为TP）
>
> **FP** 预测值大于阈值、IoU小于阈值 （对应上文，其余的预测框都为FP）
>
> **FN** 没有预测出来的目标数量
>
> **TN** 没有这个概念
>
> **GT= FN+TP**  目标总数

## Accuracy

> 无法解决目标类别不均衡问题 多目标检测不常用(多目标检测并不能保证所检测目标是均衡的)

$$
Acc = \frac{TP+TN}{TP+FP+TN+FN}
$$

## Precision

精确率、查准率   
$$
P = \frac{TP}{TP+FP}
$$

> 预测正项中真阳占比
>
> 表示模型预测正确物体的能力。
>
> 查准率越高，表明模型所预测出来的所有正例中，大部分是正确的

## Recall

召回率、查全率
$$
R=\frac{TP}{TP+FN}=\frac{TP}{GT}
$$

> 实际正项中真阳占比
>
> 表示模型找全目标物体的能力
>
> 召回率越高，表示模型能够找到更多正确的正例

**Recall和Precision之间是个矛盾的指标，当Precision高的时候，往往Recall就低。同理，当Recall高的时候，往往Precision就低。**

## $$F_{\beta}-score$$

$$
F_{\beta}-score = \frac{(1+\beta^{2})*Precision*Recall}{\beta^{2}*Precision+Recall}
$$

其中$$\beta = 1$$时 $$F_{\beta}-score = \frac{1}{2}(\frac{1}{P}+\frac{1}{R})$$ 

多类别情况下

* 宏平均

  单独计算每个类别的$$F_{1}-score$$、Precision与Recall加起来求平均

  > 默认一样的权重，实际值受到稀有类别的影响

* 加权平均

  根据每个类别占比记作类权重，将权重与 $$F_{1}-score$$、Precision与Recall相乘得到

  > 会受主要类别的影响（占比大的类别）

* 微平方平均

​	直接将每种加起来求一个总的 $$F_{1}-score$$、Precision与Recall

## P-R曲线

> 描述模型的综合性能

![image-20240805215851063](https://raw.githubusercontent.com/Thislu13/image_save/main/notebook/202408052158302.png)

横轴为查全率、召回率

纵轴为查准率、精确率

如果一个模型的P-R曲线可以包含另外一个模型，说明被包含的模型性能较差

> 曲线随置信度变化而变化，置信度指的是置信阈值，而不是IoU，IoU是固定的

## AP

通过计算P-R曲线下的面积评估模型性能 AP值越高越好

多类别的话采用mAP指标(取平均值)

## ROC曲线与AUC

>TPR   真正率  $$TPR=\frac{TP}{TP+FN}$$
>
>FPR   假正率 $$FNR=\frac{FP}{FP+TN}$$
>
>FNR  假反率 $$FNR=\frac{FN}{TP+FN}$$
>
>TNR  真反率 $$TNR=\frac{TN}{FP+TN}$$

**ROC曲线** 

设置不同的置信度阈值获得对应的 FPR 与 TPR 

横轴位FPR纵轴位TPR绘制图片

![image-20240809215548044](https://raw.githubusercontent.com/Thislu13/image_save/main/notebook/202408092155672.png)

ROC曲线上越往左上角点效果越好
