# 卷积神经网络基础

## 特征

> 平移不变性  网络的反应与特征出现的位置无关
>
> 局部性          更多的关注局部区域，不过度关注在一图像中相隔较远区域之间的关系

# 由全连接层推到卷积

* 在全连接层中

输       入  一维度向量 

经过一个  二维矩阵 

输        出  一维向量

表示为    
$$
h_{i} = \sum_{k} w_{ik}x_{k}
$$

* 卷积过程中

输       入  二维度向量 

经过一个  四维矩阵 

输        出  二维向量

表示为   
$$
h_{i,j}=\sum_{k,l}w_{i,j,k,l}x_{k,l} = \sum_{a,b}v_{i,j,a,b}x_{i+a,j+b}
$$

$$
v_{i,j,a,b} = w_{i,j,i+a,j+b}
$$

* 赋予平移不变性

在上式中 $x_{i+a,j+b}$中 $ij$  影响最终结果$h_{i,j}$ （$v_{i,j,a,b}$作为乘数，其值受到影响）并无**平移不变性**  

因此要消去$ij$对 $v$ 的影响

令  $v_{i,j,a,b} = v_{a,b}$       Kern
$$
h_{i,j}=\sum_{a,b}v_{a,b}x_{i+a,j+b}
$$
此时不同位置（具有不同$ij$）相同值的$x$能得到相同的$h$

* 赋予局部性

不关注过多的范围
$$
h_{i,j}=\sum_{a=-\Delta}^{\Delta}\sum_{b=-\Delta}^{\Delta}v_{a,b}x_{i+a,j+b}
$$
